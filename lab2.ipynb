{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Реализация классов слоев\n",
    "#### Линейный слой"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weights = np.random.randn(input_dim, output_dim) * 0.01\n",
    "        self.bias = np.zeros((1, output_dim))\n",
    "        self.input = None\n",
    "        self.grad_weights = None\n",
    "        self.grad_bias = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x  # Запоминаем для backward\n",
    "        return np.dot(x, self.weights) + self.bias\n",
    "\n",
    "    def backward(self, grad_output, learning_rate=0.01):\n",
    "        # Градиенты\n",
    "        self.grad_weights = np.dot(self.input.T, grad_output) / self.input.shape[0]\n",
    "        self.grad_bias = np.sum(grad_output, axis=0, keepdims=True) / self.input.shape[0]\n",
    "\n",
    "        # Градиент по входу\n",
    "        grad_input = np.dot(grad_output, self.weights.T)\n",
    "\n",
    "        # Обновляем параметры\n",
    "        self.weights -= learning_rate * self.grad_weights\n",
    "        self.bias -= learning_rate * self.grad_bias\n",
    "\n",
    "        return grad_input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ReLU активация"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * (self.input > 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Softmax активация"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def forward(self, x):\n",
    "        exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        self.output = exps / np.sum(exps, axis=1, keepdims=True)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        # Градиенты внешнего слоя\n",
    "        s = self.output  # Shape: [batch_size, num_classes]\n",
    "        batch_jacobian = np.einsum('ij,ik->ijk', s, -s)  # Якобиан softmax\n",
    "\n",
    "        # Добавляем диагональные элементы\n",
    "        diag = np.einsum('ij,jk->ij', s, np.eye(s.shape[1]))\n",
    "        batch_jacobian += diag\n",
    "\n",
    "        # Применение батчевого Якобиана\n",
    "        gradients = np.einsum('ijk,ik->ij', batch_jacobian, grad_output)\n",
    "        return gradients"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Loss-функция"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "    def forward(self, predictions, targets):\n",
    "        self.predictions = predictions\n",
    "        self.targets = targets\n",
    "        return np.mean((predictions - targets) ** 2)\n",
    "\n",
    "    def backward(self):\n",
    "        return 2 * (self.predictions - self.targets) / self.targets.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Вспомогательные функции"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### One-hot кодировка"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Для использования MSE нам нужно представить метки в формате one-hot:\n",
    "def one_hot_encode(labels, num_classes=10):\n",
    "    one_hot = np.zeros((labels.size, num_classes))\n",
    "    one_hot[np.arange(labels.size), labels] = 1\n",
    "    return one_hot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Загрузка данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Загружаем данные\n",
    "train_data = datasets.MNIST(root=\"/mnist-dataset\", train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.MNIST(root=\"/mnist-dataset\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "# Преобразуем в numpy\n",
    "x_train = train_data.data.numpy().reshape(-1, 28 * 28) / 255.0\n",
    "y_train = train_data.targets.numpy()\n",
    "\n",
    "x_test = test_data.data.numpy().reshape(-1, 28 * 28) / 255.0\n",
    "y_test = test_data.targets.numpy()\n",
    "\n",
    "# One-hot кодируем метки\n",
    "y_train_one_hot = one_hot_encode(y_train)\n",
    "y_test_one_hot = one_hot_encode(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Собираем нейронную сеть"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class SimpleNN:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        self.linear1 = LinearLayer(input_dim, hidden_dim)\n",
    "        self.relu = ReLU()\n",
    "        self.linear2 = LinearLayer(hidden_dim, output_dim)\n",
    "        self.softmax = Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1.forward(x)\n",
    "        x = self.relu.forward(x)\n",
    "        x = self.linear2.forward(x)\n",
    "        x = self.softmax.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad_output, learning_rate=0.01):\n",
    "        grad_output = self.linear2.backward(grad_output, learning_rate)\n",
    "        grad_output = self.relu.backward(grad_output)\n",
    "        grad_output = self.linear1.backward(grad_output, learning_rate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Обучение"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.09000763726913405\n",
      "Epoch 2, Loss: 0.0899823103539135\n",
      "Epoch 3, Loss: 0.08995383318620452\n",
      "Epoch 4, Loss: 0.08991949471630234\n",
      "Epoch 5, Loss: 0.08987644099667964\n",
      "Epoch 6, Loss: 0.08982280584517963\n",
      "Epoch 7, Loss: 0.08975447388984621\n",
      "Epoch 8, Loss: 0.08966658412618547\n",
      "Epoch 9, Loss: 0.08955202838431117\n",
      "Epoch 10, Loss: 0.089402784757451\n",
      "Epoch 11, Loss: 0.08920926480428928\n",
      "Epoch 12, Loss: 0.08896008161715818\n",
      "Epoch 13, Loss: 0.08864088971050418\n",
      "Epoch 14, Loss: 0.08823512847838107\n",
      "Epoch 15, Loss: 0.087724063326288\n",
      "Epoch 16, Loss: 0.0870867427427631\n",
      "Epoch 17, Loss: 0.08630160973414094\n",
      "Epoch 18, Loss: 0.08534751765725235\n",
      "Epoch 19, Loss: 0.08420374512295485\n",
      "Epoch 20, Loss: 0.08285000697266102\n",
      "Epoch 21, Loss: 0.08126759850994773\n",
      "Epoch 22, Loss: 0.07944580042827362\n",
      "Epoch 23, Loss: 0.07738543615177519\n",
      "Epoch 24, Loss: 0.07510364611715578\n",
      "Epoch 25, Loss: 0.07263703316184013\n",
      "Epoch 26, Loss: 0.07004028816511013\n",
      "Epoch 27, Loss: 0.06737743892259292\n",
      "Epoch 28, Loss: 0.06471269726158212\n",
      "Epoch 29, Loss: 0.06210000887757995\n",
      "Epoch 30, Loss: 0.05957715560797566\n",
      "Epoch 31, Loss: 0.057166288684568564\n",
      "Epoch 32, Loss: 0.0548758250467305\n",
      "Epoch 33, Loss: 0.05270407757088996\n",
      "Epoch 34, Loss: 0.05064778170100972\n",
      "Epoch 35, Loss: 0.048699978962184205\n",
      "Epoch 36, Loss: 0.046854450366658716\n",
      "Epoch 37, Loss: 0.04510412962194651\n",
      "Epoch 38, Loss: 0.04344417512157023\n",
      "Epoch 39, Loss: 0.04186808040281204\n",
      "Epoch 40, Loss: 0.04037145198812343\n"
     ]
    }
   ],
   "source": [
    "# Гиперпараметры\n",
    "input_dim = 28 * 28  # Размерность изображения\n",
    "hidden_dim = 64\n",
    "output_dim = 10\n",
    "learning_rate = 0.01\n",
    "epochs = 40\n",
    "batch_size = 64\n",
    "\n",
    "# Создаем сеть\n",
    "network = SimpleNN(input_dim, hidden_dim, output_dim)\n",
    "loss_function = MSELoss()\n",
    "\n",
    "# Обучение\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, x_train.shape[0], batch_size):\n",
    "        x_batch = x_train[i:i + batch_size]\n",
    "        y_batch = y_train_one_hot[i:i + batch_size]\n",
    "\n",
    "        # Прямой проход\n",
    "        predictions = network.forward(x_batch)\n",
    "\n",
    "        # Потери\n",
    "        loss = loss_function.forward(predictions, y_batch)\n",
    "\n",
    "        # Обратное распространение\n",
    "        grad_loss = loss_function.backward()\n",
    "        network.backward(grad_loss, learning_rate)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Оценка точности"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.80%\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    return np.mean(preds == labels)\n",
    "\n",
    "# Предсказания\n",
    "predictions = network.forward(x_test)\n",
    "acc = accuracy(predictions, y_test)\n",
    "print(f\"Accuracy: {acc * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8. Тестирование слоев"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Пример теста на LinearLayer\n",
    "x = np.random.randn(4, 3).astype(np.float32)\n",
    "torch_x = torch.tensor(x, requires_grad=True)\n",
    "linear = LinearLayer(3, 2)\n",
    "torch_linear = torch.nn.Linear(3, 2)\n",
    "torch_linear.weight.data = torch.tensor(linear.weights.T, dtype=torch.float32)\n",
    "torch_linear.bias.data = torch.tensor(linear.bias.flatten(), dtype=torch.float32)\n",
    "\n",
    "# Forward test\n",
    "output = linear.forward(x)\n",
    "torch_output = torch_linear(torch_x)\n",
    "assert np.allclose(output, torch_output.detach().numpy(), atol=1e-5)\n",
    "\n",
    "# Backward test\n",
    "grad_output = np.random.randn(*output.shape).astype(np.float32)\n",
    "torch_output.backward(torch.tensor(grad_output))\n",
    "grad_input = linear.backward(grad_output)\n",
    "assert np.allclose(grad_input, torch_x.grad.numpy(), atol=1e-5)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
